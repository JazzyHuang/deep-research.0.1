::: {#page0 style="width:612.0pt;height:792.0pt"}
# 深度研究平台的技术审查与[SOTA][优化方案]**

# 数据源聚合方案评估与优化**

# 现有方案概述：# 目前[
Deep Research
][网站采用了]# 多数据源并行检索# 的方案，集成了[
]# CORE# 、**[Semantic
Scholar]# 、

# OpenAlex# 、# arXiv**[
][和][
]# PubMed**[
][五大论文数据库来源]

[。检索时由一个][
]`DataSourceAggregator`[
][并发查询所]

[有启用的数据源，获取论文元数据和摘要，然后根据][
DOI
][和标题对结果进行]# 去重合并**

[。这个聚合器还具备]# 重试**

# 和后备# 机制：如果某些源检索失败，可按需重试或切换备用源，确保至少有一个数据源成功返回结果

[。聚合]

[后的结果按照一定规则（默认按引用次数）排序，并支持按最少引用数、是否开源等进行过滤]

[。这种设计最大]

[程度提高了论文搜索的覆盖面，保证系统可以找到各源中最相关或最新的论文。]

# 问题分析：# 五路并行检索虽然# 覆盖全面# ，但也带来了# 复杂性和潜在冗余# ：

# 重复数据与不一致：# 多源检索往往返回重叠的论文。尽管系统通过

[ ]

[DOI/][标题规范化去重来合并条目]

[，仍可能遇到元数据不一致的问题（例如，不同来源的摘要或作者列表不同）。目前的合并逻辑是以数]

[据完整度为优先，选取信息更丰富的版本并合并来源列表]

[。这种简单规则在大多数情况下有效，但]

[在数据冲突时可能无法保证最佳的数据质量。]

# 性能开销：# 并行调用多个外部[API][会增加]# 延迟和流量# 消耗，尤其当其中某些源响应较慢或限流时。虽然聚合

[器实现了]# 并行处理和超时机制# （每个源有设定的超时，并行等待所有源返回或超时）

[，]["][广撒网]["][式]

[的检索可能比单一数据源慢，并增加了对各][API][的依赖和故障处理复杂度]

[。在实际使用中，如果用户]

[查询频繁且每次都请求][5][个源，这对系统和外部][API][都造成较大压力。]

# 数据质量与相关性：# 不同数据库对查询的# 相关性排序# 算法各异，返回结果质量参差不齐

[。例如，]

[Semantic Scholar
][使用][
AI
][提升相关性，往往能更快提供更精确的结果]

[；][OpenAlex
][则更偏重元数据匹]

[配，可能返回较宽泛的结果。简单地合并所有结果再按引用数排序]

[，未必总是最符合查询意图的最]

[佳排序。一些高被引论文可能和具体查询关系不大，而相关度高但新颖的论文引用少，可能在排序中被淹]

[没。]

# 优化建议：**

# 智能来源选择# ：根据查询主题动态调整数据源组合，以减少不必要的开销和噪音。例如，可通过分析用户查

[询的领域关键词，]# 有针对性地选择源**

[：]

[若查询偏生物医学，则重点使用
]# PubMed**[（以及
][Semantic
Scholar
][等）而减少调用计算机科学偏重的]

[arXiv][。]

[若查询包含物理][/][数学预印本内容，则优先使用
]# arXiv**[
数据。]

[对于跨学科或一般性主题，则依然可以启用多源保证覆盖面。]

[这种]# 按域选源# 的策略可通过简单规则或训练一个分类模型实现。它能在保持结果质量的同时减少无关源的调用，提

[高效率并降低去重负担。类似思路在一些学术搜索聚合平台上已有体现，例如][
Lens
][平台综合了][
PubMed][、]

[1]

[2]

[3]

[4]

[5]

[• ]

[6]

[7]

[8]

[9]

[• ]

[10]

[11]

[3]

[4]

[• ]

[12]

[13]

[14]

[15]

[1. ]

[16]

[2. ]

[3. ]

[4. ]

[1]
:::

::: {#page0 style="width:612.0pt;height:792.0pt"}
[CrossRef][、][OpenAlex
][等数据源且提供强大过滤功能]

[，但用户可根据需要选择特定领域数据库，以提高相关性]

[和减少杂讯。]

# 利用综合性平台[/API][：]# 考虑引入**[更高层次的聚合
][API]**[
来简化流程。例如
]# OpenAlex**[
本身整合了
][CrossRef
][元]

[数据和
][Unpaywall][开源全文等信息，几乎覆盖了已发表论文的大部分元数据]

[。][OpenAlex][返回的数据包]

[括论文的
][DOI][、引用计数、主题分类、开放获取链接等。如果以
][OpenAlex
][作为主要数据源，可以获取较全]

[面的论文列表，然后：]

[利用其提供的
][DOI
][列表通过
]# CrossRef**[
补充元数据和引用关系（][CrossRef
][对][DOI][的元数据极为权威）。]

[结合
]# Unpaywall**[
或
][CORE
][获取开放获取全文链接（实际上][OpenAlex][已包含部分][Unpaywall][数据）。]

[在需要时，再针对少数][OpenAlex][找不到的特殊内容调用其他源作为补充（例如
][arXiv][仅有预印本][ID][而无][DOI]

[的情况、或][PubMed][收录的医学会议摘要等）。]

[这样可以]# 减少同时维护多个[API][调用]# 的复杂性，将主要精力放在一个聚合源上，再做少量补充。这类似于将当前多

[路并行改为]["][一主多辅]["][。权衡是依赖单一聚合源可能漏掉一些最新或未收录的数据，但][OpenAlex][等开源平台覆盖率]

[相当高]

[且不断更新维护，可满足大部分需求。实际中，][Deep]

[ ]

[Research][已经在无][API][密钥时默认使用]

[OpenAlex][、][arXiv][、][PubMed
][这三个免费源组合]

[；我们可以进一步强化这一思路，把][OpenAlex][提升为核心入]

[口，将][CORE][和][Semantic
Scholar][作为特定场景下的补充，以]# 瘦身聚合层# 。

# 本地缓存与索引：# 引入# 查询缓存和本地索引# 机制，减少重复检索开销。很多用户提出的研究问题可能相似或

[重复。可以：]

[对用户查询和返回结果建立缓存映射，在短时间内相同查询直接返回缓存结果并异步更新。]

[将高频查询的论文结果存入]# 本地数据库[/][索引]**[（例如使用
][ElasticSearch
][或向量数据库），对这些常见主题的]

[初步搜索可以本地完成，再结合实时][API][获取更新。
]

[对于多轮检索过程中产生的中间结果（比如][Planner][拆分的子问题），也可在][session][范围缓存，以免]

[Researcher
Agent][多次搜索相同关键词。]

[缓存需要注意缓存失效策略（例如学术数据定期更新的问题），但在短期迭代中可以明显降低][API][调用量。]# 结果缓存**

[属于业界常见的性能优化，在][Deep
Research][场景下也很适用。]

# 改进去重和合并逻辑：**[目前通过
][DOI
][和标题近似匹配去重已经基本解决了重复问题]

[。可以考虑的进]

[一步优化包括：]

# 更智能的合并**[：引入文本相似度算法对标题进行模糊匹配，以捕捉那些无
][DOI
][但实际是同一论文的情况]

[（例如
][arXiv
][预印本
][vs
][期刊正式出版物）。目前系统截取标题前][100][字符做简单归一化比较]

[。可改用编]

[辑距离或][embedding][相似度判断标题是否实质相同，减少漏判][/][误判。]

# 数据字段取舍策略# ：合并两条记录时，当前逻辑简单以["][数据][Availability][等级]["][决定谁为][base]

[。可以更细]

[粒度地]# 字段级融合# ：例如作者列表可以合并去重，摘要可以选择长度更长者但同时检查是否包含更多信息

[等。这样避免因为一方缺少某字段就完全舍弃，最大化保留所有来源的信息。虽然这些改进复杂度较高，在]

[多数情况下默认策略已够用，但对于追求高数据质量的平台，可作为改进方向。]

# 借鉴学术搜索最佳实践：# 学术文献元搜索是研究人员常见需求，也有一些成熟工具和研究可借鉴。例如：

# 结果相关性融合**[:
][学术元搜索引擎有时会对不同来源的结果进行学习排序，而非按单一维度排序。可以考虑]

[训练一个简单的机器学习模型，根据论文的来源得分（如][Semantic
Scholar][的相关度分、][OpenAlex][的引文]

[数等）、论文发布时间、新旧程度等，对合并后的结果进行二次排序，可能比纯引用数排序更贴合用户查询]

[意图]

[。]

[17]

[1. ]

[18]

[2. ]

[3. ]

[4. ]

[12]

[18]

[1. ]

[2. ]

[3. ]

[4. ]

[1. ]

[19]

[7]

[2. ]

[20]

[3. ]

[21]

[4. ]

[5. ]

[12]

[2]
:::

::: {#page0 style="width:612.0pt;height:792.0pt"}
# 综合评价指标**[:
][例如同时参考]# 引用次数# 和# 文章发表年份# ，避免全部老论文占据前列[------Deep
Research][已经]

[支持按年份排序和给予]["][新近度]["][评分]

[。进一步可考虑在聚合阶段就应用这些标准筛选：如移除引用少且]

[偏旧的结果，或保证结果列表在时间上多样化以覆盖最新进展。]

# 充分利用各源特色**[:
Semantic
Scholar][提供]# TLDR[摘要]# 和# 高影响引用# 等[AI][增强信息]

[；][OpenAlex][提供]

# 论文主题分类# ；这些额外信息可以在后续过滤中发挥作用。例如，可以用[Semantic
Scholar][的影响力评分来]

[加权排序]

[，用论文主题来确保结果涵盖查询相关的不同子方向，而不过于集中在单一主题上。]

[综合来看，现有多数据源策略虽然显得]["]# 臃肿# "[，但它确保了学术搜索的]# 广度# 和# 容错# （任一源失效还有其他来源）。

[优化方向应在]# 不牺牲覆盖范围和新鲜度# 的前提下，# 精简冗余调用# 和# 提高相关性# 。通过# 智能选源# 和# 借助综合平台# 可降

[低系统复杂度，通过]# 缓存和学习排序# 可提升性能和结果质量。这样一来，数据层既能保留多源优势，又更加高效可

[靠，不会因为追求全面而降低用户体验。]

# 前端界面现代化改进（[Vercel
AI SDK v5
][等）]**

# 现有界面分析：**[
Deep Research
][前端采用][
Next.js
][与][
React
][技术栈，使用了][
Tailwind CSS
][和][
shadcn/UI
][组件库，]

[具备实时][
SSE
][流式更新和][
Agent
][执行时间线可视化等功能]

[。目前界面实现了一个]# Agents[执行面板]# 展示多代理

[的执行进度，支持逐步追踪研究过程，并提供交互的研究会话管理]

[。然而，随着][
Vercel AI SDK v5
][的发布和]

[Cursor IDE 2.0
][等先进界面的出现，我们有机会让前端][UI][更加现代、美观，提升用户的交互体验。以下是具体的改]

[进思路：]

**[采用
][Vercel
AI SDK v5
][的
][AI
Elements
][组件：]**[Vercel
AI SDK 5
][引入了]**[AI
Elements]# 组件库，这是建立在

[shadcn/ui
][之上的一组预构建且可定制的
][React
][组件]

[。它提供聊天界面常用的]# 消息线程# 、# 输入框# 、# 思路**

# 面板# 、# 响应区# 等[UI][原件]

[。利用这些组件可以快速重构
][Deep
Research
][的对话及][Agents][显示界面，优势]

[包括：]

# 开箱即用的对话布局：**[使用
]`Message`[
、]`MessageContent`[
、]`Response`[
等组件，可以方便地渲染带]

[有流式响应的消息列表]

[。这比手写
][JSX
][更简单，并且与
][SDK
][的状态管理（如
]`useChat`[
钩子）无]

[缝结合]

[。这样可以更可靠地实现聊天消息的逐字流出效果和错误处理]

[。]

# 一致的视觉风格：**[AI
Elements
][基于
][shadcn/ui
][构建，保证了与现有
][Tailwind
+ shadcn
][设计体系的一致性]

[。默认样式简洁现代，同时开发者可以完全控制样式细节，轻松定制以匹配我们品牌。相比之下，自己]

[构建可能在风格和交互细节上花费更多时间。]

# 多样的[AI][交互模式支持：]**[AI
Elements
][不仅限于基本聊天，还支持]# "[推理面板]["]# 等更复杂的[AI][界面模式]

[。例如，我们可以用
][ReasoningPanel
][来显示
][Agent
][的思考过程，用
][ToolUse
][显示工具调用结果等。]

[这非常契合
][Deep
Research
][中需要展示
][Agents][内部步骤和理由的需求，能够比纯文本聊天框更清晰地呈现]

[复杂过程。]

[具体实施上，我们可以参考][
Vercel
][提供的教程将界面组件替换为][
AI
Elements]

[。比如，将当前研究会话的消息]

[渲染逻辑替换为][
]`<Message>`[
][列表，根据][
agent
][角色（][user/system/assistant][或自定义角色）区分样式]

[。对于][
Agents
][面板，则可利用][
Elements
][提供的]# 多段消息# 和# 工具输出# 支持，在界面上将每个阶段的结果划分为

[清晰的模块（如][
Planner
][的计划、][Researcher
][找到的论文列表、][Writer
][起草的段落等），通过不同样式或图标加]

[以区别。]

**[借鉴
][Cursor
2.0
][的
][Agents
][交互设计：]**[Cursor
IDE 2.0
][的界面将]# Agent-centric# 设计发挥得淋漓尽致，可作

[为我们优化交互的蓝本]

[。值得学习的要点包括：]

# 侧边栏[/][标签页式的
][Agent
][管理：]**[Cursor
2.0
][引入了专门的
][Agents][侧栏，列出所有][Agent][，让用户可以快速]

[在多个][Agent][视图间切换，查看各自的运行状态和输出]

[。对于
][Deep
Research][，我们也可以实现类似的]

# 阶段切换[/][展开界面]# ：例如在侧边栏显示["Planner][、][Researcher][、][Writer][、][Critic][、][Validator"][等角色标签，]

[6. ]

[22]

[7. ]

[13]

[23]

[23]

[24]

[24]

[1. ]

[25]

[25]

[2. ]

[26]

[27]

[28]

[29]

[30]

[3. ]

[25]

[4. ]

[25]

[31]

[32]

[33]

[34]

[1. ]

[35]

[36]

[2. ]

[35]

[3]
:::

::: {#page0 style="width:612.0pt;height:792.0pt"}
[用户点击即可展开查看对应阶段的详情输出。每个][Agent][的输出可以是一个富文本面板，包含其关键动作和]

[结论摘要。当不需要细看时也可折叠，只关注最终报告。这种]# 多[Agent][并行框架]# 即使在[Deep
Research][不是]

[同时并行运行，也可以加强]# 分阶段呈现# ，让用户对流程一目了然。

# 输出审查与反馈界面：# Cursor[提供了方便的视图来]# 审查[Agent][对代码的改动]# 等结果

[。类比到我们的]

[网站，我们可以在
][Critic/Quality
Gate
][阶段加入一个]# "[审查点]["]# UI[：显示
][Critic
Agent
][给出的评价（如覆盖率]

[评分、是否有幻觉等）以及
][Quality
Gate
][的决策（是否需要迭代）。这样用户可以直观看到][AI][对自身回答的]

[反思。甚至，我们可以提供一个]# 人工干预按钮# ，允许用户在[Quality
Gate][阶段手动要求再搜索或修改某部]

[分。这类似于人为插入一个审查点，提高交互灵活性（当然默认可自动通过）。]

# 执行过程可视化：# Cursor[的][Agent][执行面板实时展示每个][Agent][的运行进度，并支持查看日志细节]

[。]

[Deep
Research][已实现基本的步进显示和进度提示，但可进一步]# 强化视觉呈现# 。例如，引入# 时间轴式动画# ：

[每当][Agents][切换阶段时，在界面侧边时间轴增加一个节点，标注时间戳和阶段名称（如]["Researcher:
][完成]

[第][2][轮搜索，找到][5][篇论文]["][）。节点展开可显示具体操作内容和引用的文献列表，收起则只显示阶段概览。]

[这种时间轴不仅美观，还增强了]["AI][在为我工作]["][的临场感。]

[通过借鉴以上思路，我们的界面将更符合]# 以任务[/Agent][为中心]# 的交互范式，让用户专注于研究过程和结果，而非技

[术细节。用户可以]# 自由浏览[AI][的思维过程]# 或选择信任自动流程，两相兼顾，正如[
Cursor
][强调的]["][聚焦目标，细节由]

[AI][处理]["]

[。]

# 提升用户体验的细节与动效：**

# 现代化视觉风格：# 在引入新组件后，可全面优化配色和布局，使之更# 简洁清爽**[。使用
][Tailwind
][配合]

[shadcn][，可实现类似
][Cursor
][那种极简却不失重度信息的风格。比如，采用卡片式布局显示论文条目、使用]

[悬浮提示显示引用信息等，让界面信息密度高但不杂乱。]

# 动画和过渡效果：**[利用
]**[Framer
Motion]**[
或
][CSS
][动画，为界面添加细腻的过渡。例如在][Agent][输出更新时淡]

[入淡出新文本，在阶段切换时侧边标签高亮闪烁提示，或在等待][AI][思考时显示优雅的进度条][/][旋转图标。这]

[些动画不会改变功能但能提升]# 品质感# ，让用户感觉流程流畅连贯。特别是当系统进入审查和二次迭代时，用

[一些视觉暗示（例如][Quality
Gate][节点变为橙色警示再转为绿色通过）来表示]["AI][正在自我批评和改进]["][，增]

[强用户对背后复杂流程的理解和参与感。]

# 交互与控制：# 确保界面提供足够的# 可控点# 但不干扰自动流程。例如，允许用户在生成过程中暂停或终止（万

[一等待太久），或者提供]["][展开更多细节]["][按钮以显示完整的][AI][推理日志。如果用户希望][Deep
Research][不仅]

[给结论，也展示分析过程，我们的][UI][应该让深度内容随取随有。这方面可以参考
][Cursor
][提供在经典编辑器]

[和][Agent][布局间切换的能力，让专业用户和普通用户都能得到满足]

[。]

# 响应式和跨设备支持：# 确保新的界面在不同尺寸屏幕上良好适配。研究报告和[Agent][面板内容较多，在移动]

[端需要折叠为垂直流式布局；桌面端则可以左右分栏（例如左侧侧栏][+][主要内容区）。][Vercel][的组件和]

[Tailwind][的工具类能帮助快速实现响应式，我们要注意测试不同场景下的体验，使交互]# 一致且顺畅# 。

[综上，前端升级应充分利用]**[Vercel
AI SDK
v5]# 提供的强大组件，极大减少我们造轮子的工作，把时间投入在设计# 优**

# 秀的交互体验# 上。结合[
Cursor 2.0
][的范式，我们能够打造一个]# 现代化、直观# 的研究[AI][界面：既有对话机器人的易用]

[性，又具备专业科研工具的过程透明度，让用户在使用中感到愉悦、高效。]

**[数据处理流程与多
][Agent
][架构的优化]**

# 现有架构概览：**[Deep
Research][采用了]# 多智能体协作# 的架构，将复杂的学术研究任务拆分给不同职责的[Agent][顺序]

[执行]

[。具体包括：由][
]# Coordinator**[
][统筹决策，]# Planner**[
][解析问题制定搜索策略，]# Researcher**[
][多轮检索论文，]

# Writer**[
][撰写报告，]# Critic**[
][审核质量，]**[Quality
Gate]**[
][衡量指标决定是否迭代，最后][
]# Validator**[
][核实引用正确性]

[。整个][Pipeline][形成了一个闭环的流水线，如架构图所示，从规划→搜索→写作→质检→反馈，必要时循环多次]

[。这种]# 模块化、多[Agent][链路]# 设计，使每个阶段都有针对性的处理逻辑，看似复杂但实际上遵循了# Plan-and-**

[3. ]

[37]

[38]

[4. ]

[39]

[35]

[1. ]

[2. ]

[3. ]

[4. ]

[40]

[5. ]

[41]

[41]

[42]

[4]
:::

::: {#page0 style="width:612.0pt;height:792.0pt"}
# Execute# 的先进模式，将任务规划与执行解耦

[。整体而言，该架构体现了当今复杂][AI][任务][
orchestration
][的]

[前沿思想，以下从优化和][SOTA][对比角度来审视：]

# 验证架构合理性：# 多[Agent][架构本身符合当前业界对]# 复杂任务分而治之# 的理念。例如，[Plan-and-Execute][代]

[理被认为比单一][ReAct][代理在长任务上更高效、更准确]

[。][Deep]

[ ]

[Research][的]

[Planner+Researcher+Writer][链条正是]# 先规划后执行# 的体现：[Planner][列出子任务][/][检索策略，][Researcher][逐]

[步执行获取资料，][Writer][再整合成文。这种先规划再执行的模式有助于减少无谓的循环和上下文长度]

[。相比传统][ReAct][每步都在思考下一个动作，][Planner][提前拟定整体方案使代理行为更全局优化，降低遗]

[漏重要分支的风险]

[。因此，][Deep
Research][的处理流程理念是]# 先进且正确# 的，无需推倒重来。我们

[的优化重点应放在]# 细节改进# 和# 新技术融合# 上。

# 减少冗余与冲突：# 检查各[Agent][职责是否有重叠或矛盾：]

**[Planner vs
Researcher][：]# Planner[产出搜索计划后，][Researcher][根据计划执行。但目前][Planner][和]

[Researcher][可能都涉及一定程度的检索内容筛选（][Planner][挑选关键词、][Researcher][也需要根据摘要筛选有]

[用论文）。考虑是否]# 合并部分职责# 或者让[Planner][产出更明确的筛选标准，减少][Researcher][的不确定性。也]

[就是说，让][Planner][尽可能细化，例如指定需关注哪些章节或判断标准，让][Researcher][主要执行而非再决]

[策。这可以通过强化][Planner
prompt][来实现，使其输出例如]["][搜索
][X
][领域近][5][年高被引论文，并关注其中方]

[法比较部分]["][之类的策略。这样][Researcher][步骤会更精准，不会与][Planner][逻辑重复。]

**[Critic vs Quality
Gate][：]**[当前
][Critic
][用][LLM][对报告做质检、给出评分和问题，][Quality
Gate][基于这些和预设]

[指标决定是否迭代]

[。两者配合实现了]# 自我反馈**[，相当于近期提出的
]*[Self-Refine]*[
方法，让][LLM][自我评估并]

[改进输出]

[。这非常符合][SOTA][，无明显冲突。但可以考虑]# 合并角色以节省轮次**[：例如直接由
][Critic
][给出改]

[进建议，然后让
][Writer][进入下一轮执行，而][Quality
Gate][的通过][/][不通过决策融入][Critic][反馈中。这么做可以]

[少调一次模型（减少开销），但缺点是][Critic][本身可能不易量化得分。保留][Quality
Gate][有助于引入]# 可量化指**

# 标# （覆盖率、引用密度等）

[，对迭代停止条件更可控。所以目前拆分是合理的，不建议完全合并。不]

[过，我们可以让两者在实现上]# 并行工作# ：在[Writer][出稿后，同时启动][LLM][评估（][Critic][）和指标计算]

[（][Quality
Gate][）以节省时间，然后综合结果。这要求架构支持并行][Agent][执行，稍加改造即可实现更高效]

[的管线。]

**[Validator
][独立性：]**[Validator
][目前专注引用的后验验证]

[。这一步和前面内容生成分离是正确的，因为引]

[用核查需要访问][
CrossRef
][等进行][DOI][校验]

[。这里没有冗余，但可以加强的是]# 引用对内容的匹配检查# （即

[验证引用的论文内容是否支持文本陈述）。这属于更高级的语义验证，目前系统未实现，是潜在提升点，但]

[也需要][NLP][对比引用文本和报告句子的技术，比较前沿复杂。作为起步，][Validator][可增加]# 引用格式统一# 、# 死**

# 链检查# 等功能，保证输出报告在引用部分万无一失。

# 引入最新技术和框架：# 持续跟踪[LLM][代理领域的新进展，结合到我们的][pipeline][中，使其保持][SOTA][水准：]

# 自我反思与持续改进[:]**[
如前所述，][Deep
Research][已经实现了让][AI][自评再迭代，这与近期研究的
]*[Self-Refine]*

[方法不谋而合]

[。可以考虑让这个过程更智能：比如][Critic][在找问题时，不仅给总体分，还可分类别给]

[出]["][覆盖不足哪些方面][""][引用有无不准确]["][等具体反馈，让下一轮][Planner][能针对这些]# 发现的空白（[Gap][）]# 制定

[新的检索计划，从源头完善答案。这相当于把][Critic][反馈融入][Planner][，形成]# 反馈环路# ，比仅由[Quality
Gate]

[触发]["][再搜几篇]["][更有指向性。这种基于][LLM][反馈的调整逻辑在业界属于前沿方向，即利用模型自己的反馈指]

[导下一步动作]

[。实现上，可以解析][Critic][输出的评语，用规则或小模型分析出需要的新子问题，然后]

[Planner][新增这些子问题去搜索]

[（事实上][Deep
Research][已经有]["Gap
analysis with automatic
search]

[suggestions"][的设计]

[,
][我们应确保将][Critic][信号充分用于此功能][)][。]

[43]

[44]

[1. ]

[45]

[43]

[44]

[46]

[47]

[2. ]

[3. ]

[4. ]

[48]

[49]

[22]

[5. ]

[50]

[51]

[6. ]

[7. ]

[49]

[52]

[53]

[54]

[54]

[5]
:::

::: {#page0 style="width:612.0pt;height:792.0pt"}
# Agent[框架与调度：]# 目前[Agents][之间的调用顺序和信息传递由][Coordinator][用固定逻辑编排。可以尝试采用]

# 通用[Agent
Orchestration][框架]**[来管理，例如微软的
]# Autogen**[
框架或
][LangChain
][的多][Agent][调度模块]

[。这些框架提供了现成的]# 消息路由、并行管理# 、错误恢复等功能，可以简化我们定制逻辑的负担，并更

[容易扩展出新][Agent][。比如，如果将来增加一个
][Evidence
Checker Agent
][来逐段核对内容，我们可以借助]

[框架把它插入合适位置并行工作，而不是手动修改大量协调代码。当然，引入外部框架也有学习成本，如果]

[现有][Coordinator][逻辑易于维护，则保持自主实现也未尝不可。但关注这些框架的思路，能启发我们更好地]

[设计][Agent][之间通信协议，避免耦合和状态不一致。]

# 长上下文和记忆管理：# 科研报告可能涉及许多论文，[Token][上下文长度容易爆表。当前系统通过]

[ContentExtractor
][对不同阶段只提取所需的信息片段来控制上下文]

[，并在需要全文分析时才获取全]

[文且做截断]

[。这是非常必要的优化。此外，可以考虑引入]# 向量数据库# 来存储已获取的论文内容

[Embedding][，用于语义检索和上下文检索：]

[例如，当][Writer][生成报告某部分时，如果能将相关论文的][embedding][向量召回，比简单地拼接全文]

[更加精准。我们可以将][PaperCache][中的全文段落向量化，][Writer][提问某小结需要细节时，从向量][DB]

[中找最相关的段落内容加入上下文。这类似于
][Retrieval-Augmented
Generation (RAG)
][的做法，能]

[够提升信息检索的语义准确性。]

[另外，]# 记忆[Agent]# （[Memory
Agent][）：][Deep
Research][有一个][Memory][模块负责会话记忆]

[。我]

[们可以扩展其能力，让系统在多轮迭代中保留]["][哪些要点已经写过][/][有哪些已处理过的参考文献]["][。这]

[样避免再次搜索相同内容，也防止][Writer][重复啰嗦。][Memory][模块可以利用][embedding][技术高效存]

[储已讨论内容摘要，后续][Agent][决策时查询，做到]# 不重复劳动# 。

# 并行化与异步优化[:]**[
当前大部分步骤是串行的，但存在可以并行的空间。例如：]

[在某轮搜索中，可以并行调用各数据源（这已实现）以及在拿到][paper][列表后，可以并行触发]

[PaperEnricher][去获取多篇候选论文的全文（目前][PaperEnricher][似乎按需处理一篇，提高重要论文]

[获取速度的话可考虑并发获取多篇全文，只取回必要部分）。]

[多][Agent][并行：虽然规划→检索→写作必须有顺序依赖，但]# 质检和验证# 步骤可以与# 后续[UI][渲染]# 并行。

[例如在][Writer][写完初稿的同时，][Critic][已经开始审稿，这样总时间减少。甚至可以尝试]# 多个[Writer][并]**

# 行撰写不同段落# 然后合并，不过这复杂度较高、需要解决风格一致性，可以留待以后探索。

[Cursor 2.0
][的设计中允许]# 多个模型[/Agent][并行尝试解决同一问题并取最佳]**

[。在][Deep]

[Research][场景，我们或可尝试]# 并行调用不同[LLM][来撰写报告]# 或回答不同子问题，然后通过[Critic][评分]

[选择最优答案片段组合。这虽然增加开销，但在要求极高质量时不失为一种][SOTA][思路（类似于]["][让多]

[个][AI][头脑风暴，取其精华]["][）。实践中可以限定只在第一轮写作时启用两个不同风格模型并行（例如]

[GPT-4][和一个领域特化模型），比较输出后选定一个进行后续迭代。]

# 新技术探索：# 学术研究助理是前沿应用领域，可以关注引入一些# 最新研究或产品# ：

# 知识图谱结合：**[利用学术知识图谱（如
][OpenAlex
][提供的引用][/][作者网络）辅助][Agent][决策。例如，][Planner]

[确定重点文献时，可根据论文的引用网络找到领域内公认的关键文献（]["][高引经典]["][或者]["][里程碑]["][）。这可通]

[过][OpenAlex][的引用计数和关联][API][实现，在制定搜索策略时就考虑引用网络信息，比纯关键词搜索更有深度]

[。这使][Agent][更像一个有经验的研究员，知道先读哪些代表性工作。]

# 领域自适应模型：# 随着开源大模型发展，我们可考虑引入针对学术领域优化的模型（如[SciGPT][类）参与部分]

[Agent][工作，以降低对远程][API][的依赖并加快响应。此外，][OpenAI][等模型的插件机制也值得关注，未来或可]

[通过插件直接查询学术数据库，让][LLM][自主决定调用，这也是][Agentic
AI][的一大趋势。]

# 安全与可靠性：# 确保[Agent][不给出不当内容（比如幻觉引用或错误解读论文）。这一部分可在][Critic][阶段加]

[强，比如增加]# 事实核对[Agent]# 。近期一些系统（如[Microsoft
Bing
Chat][）会将引用片段和生成内容对照，标]

[记不一致之处。我们可以尝试用类似方法，至少在内部对引用内容进行片段核查，哪怕不向用户展示，也可]

[作为][Quality
Gate][的另一维度评分，提升最后输出可信度。]

[8. ]

[55]

[9. ]

[56]

[57]

[58]

[59]

[◦
]

[◦
]

[60]

[10. ]

[◦
]

[◦
]

[◦
]

[61]

[62]

[11. ]

[12. ]

[12]

[13. ]

[14. ]

[6]
:::

::: {#page0 style="width:612.0pt;height:792.0pt"}
# 总结优化方案：**[Deep
Research
][的][pipeline][已经实现了]# 多[Agent][协作、循环自检]# 等先进特性，在技术上相当具有前

[瞻性。我们的调研并未发现架构上明显缺陷，更多是在]# 优化细节和拥抱新技术# 上有提升空间。通过# 动态选源、精简**

# 聚合# 提升数据层效率，通过# 升级[UI][交互]# 提高用户体验，通过# 强化[Agent][协同与引入前沿算法]# 提升生成内容质量和可

[靠性，我们可以将该平台打造成业界领先的学术研究][AI][助手。]

[综上所述，本报告提出了从数据获取到前端展示、再到智能体流程的全方位优化方案。这些建议结合了当前最新的]

[研究动向和业界最佳实践，旨在让][
Deep Research
][平台更高效智能、易用美观，真正达到]# SOTA[级别]# 的学术研究助

[理水准。]

# 参考文献：**

[Deep Research
][项目源码和文档]

[等
]

[业界相关技术博客和论文，如
][Cursor
2.0
][发布博客]

[、][Vercel
AI SDK
Changelog]

[、][ReAct
vs Plan-]

[and-Execute
][对比]

[、][Self-Refine
][方法论文]

[等。
]

[• ]

[41]

[2]

[3]

[21]

[• ]

[35]

[25]

[43]

[44]

[49]

[7]
:::

::: {#page0 style="width:612.0pt;height:792.0pt"}
[README.md]

[https://github.com/JazzyHuang/deep-research.0.1/blob/900f7d264f7e256ef7f34cdf64d12546e647bb9e/README.md]

[index.ts]

[https://github.com/JazzyHuang/deep-research.0.1/blob/900f7d264f7e256ef7f34cdf64d12546e647bb9e/src/lib/data-sources/]

[index.ts]

[The Petrol Tank for AI Discovery Might be Running Dry as
\...]

[https://aarontay.substack.com/p/the-petrol-tank-for-ai-discovery]

[Open Research Platforms -- Part 1 \|
openscience.eu]

[https://www.openscience.eu/node/23]

[Introducing AI Elements: Prebuilt, composable AI SDK components -
Vercel]

[https://vercel.com/changelog/introducing-ai-elements]

[AI SDK 5 -
Vercel]

[https://vercel.com/blog/ai-sdk-5]

[From Developer to Delegator: Inside Cursor
2.0]

[https://inkeep.com/blog/cursor-2-review]

[New Coding Model and Agent Interface ·
Cursor]

[https://cursor.com/changelog/2-0]

[ReAct vs Plan-and-Execute: A Practical Comparison of LLM Agent Patterns
- DEV
Community]

[https://dev.to/jamesli/react-vs-plan-and-execute-a-practical-comparison-of-llm-agent-patterns-4gh9]

[Navigating Modern LLM Agent Architectures - Wollen
Labs]

[https://www.wollenlabs.com/blog-posts/navigating-modern-llm-agent-architectures-multi-agents-plan-and-execute-rewoo-tree-]

[of-thoughts-and-react]

[Self-Refine: Iterative Refinement with Self-Feedback -
arXiv]

[https://arxiv.org/abs/2303.17651]

[madaan/self-refine: LLMs can generate feedback on their \... -
GitHub]

[https://github.com/madaan/self-refine]

[content-extractor.ts]

[https://github.com/JazzyHuang/deep-research.0.1/blob/900f7d264f7e256ef7f34cdf64d12546e647bb9e/src/lib/content-]

[extractor.ts]

[1]

[2]

[16]

[18]

[22]

[24]

[41]

[42]

[48]

[50]

[51]

[54]

[60]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[14]

[15]

[19]

[20]

[21]

[12]

[13]

[17]

[23]

[25]

[26]

[27]

[28]

[29]

[31]

[32]

[33]

[34]

[30]

[35]

[36]

[39]

[40]

[55]

[61]

[62]

[37]

[38]

[43]

[44]

[46]

[47]

[45]

[49]

[52]

[53]

[56]

[57]

[58]

[59]

[8]
:::
